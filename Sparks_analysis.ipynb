{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis sparks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Imagenes_confocal/Rata/C071112/'\n",
    "photo_name = 'c3ack009'\n",
    "x_calibracion = 4.5\n",
    "\n",
    "# import numpy as np                # funciones numéricas (arrays, matrices, etc.)\n",
    "import matplotlib.pyplot as plt   # funciones para representación gráfica\n",
    "%matplotlib inline\n",
    "# import cv2\n",
    "# from PIL import Image\n",
    "import pandas as pd\n",
    "import  csv\n",
    "#     '''This function finds a tList in sec yList - measurements ySS - the steady state value of y returns amplitude of exponent tau - the time constant'''\n",
    "from math import log\n",
    "from pylab import lstsq\n",
    "from pylab import matrix\n",
    "from pylab import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b9aed5f771c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msparks_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msparks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparks_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mphoto_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".tif\"\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# Read image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import sparks_image\n",
    "\n",
    "sparks = sparks_image()\n",
    "image = cv2.imread(path + photo_name + \".tif\")    # Read image\n",
    "\n",
    "if imag is None:\n",
    "    print(\"Check file path\")\n",
    "else:\n",
    "    r = sparks_image.select_roi (image) # Select ROI\n",
    "    imCrop = sparks_image.crop_image (image, r)    # Crop image\n",
    "    sparks_image.display_image ('Image' , imCrop)    # Display cropped image\n",
    "        \n",
    "auto_result, alpha, beta = sparks_image.automatic_brightness_and_contrast(imCrop)\n",
    "cv2.imshow('auto_result', auto_result)\n",
    "cv2.imshow('image', imCrop)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "dilate = sparks_image.filtration (auto_result)[0]\n",
    "original = sparks_image.filtration (auto_result)[1]\n",
    "\n",
    "cnts = sparks_image.find_contourns (dilate)    # Find contours\n",
    "\n",
    "# Iterate thorugh contours and filter for ROI\n",
    "list_img_col = []\n",
    "track_number = 0\n",
    "for c in cnts:\n",
    "    img_col_mean = sparks_image.track_contours (c, auto_result, track_number) [0]\n",
    "    track_number +=1\n",
    "    list_img_col.append (img_col_mean)\n",
    "#     plot_histogram (img_col_mean, nombre_foto, \"time\", \"Intensity\")    #gráfico de histograma\n",
    "\n",
    "#     cv2.imwrite(\"ROI_{}.png\".format(track_number), ROI)\n",
    "#     track_number += 1\n",
    "\n",
    "sparks_image.display_image ('image' , auto_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from __future__ import print_function\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display\n",
    "\n",
    "img_bc = interactive(f, brightness=100, contrast=100)   #display brightness and contrast\n",
    "display (img_bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "im = rotation (imCrop, 90)    # rotate image\n",
    "display_image ('Image' , im)    # Display cropped image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Aplicación de análisis sobre picos** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximo_peak (vector):\n",
    "    import numpy as np\n",
    "    from peakutils.peak import indexes\n",
    "    import peakutils\n",
    "    indexes = indexes(np.array(vector), thres=1.0/max(vector), min_dist=10)\n",
    "    kk = list(indexes)\n",
    "    for j in kk:\n",
    "        if vector[j]> (sum(vector) / len(vector)):\n",
    "            tiempos = j\n",
    "            intensidades = vector[j]\n",
    "    return tiempos,intensidades\n",
    "\n",
    "cantidad_sparks = len(list_img_col)\n",
    "\n",
    "datos_tiempos = {}\n",
    "datos_intensidades = {}\n",
    "\n",
    "for i in range (0,cantidad_sparks):\n",
    "    picos = maximo_peak (list_img_col[i])\n",
    "    datos_tiempos [i] = picos [0]\n",
    "    datos_intensidades [i] = picos [1]\n",
    "    \n",
    "\n",
    "Columns = ['Spark_'+ str(x) for x in range(0, cantidad_sparks)]\n",
    "out_sparks = pd.DataFrame([datos_tiempos.values(),datos_intensidades.values()], columns = Columns).T\n",
    "out_sparks = pd.DataFrame(out_sparks.values, columns = ['tiempo_maximo', 'intensidad_maxima'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Detección de mínimos locales\n",
    "# Calculate the n-th discrete difference along the given axis. The first difference is given by out[i] = a[i+1] - a[i] along the given axis, higher differences are calculated by using diff recursively.\n",
    "# The sign function returns -1 if x < 0, 0 if x==0, 1 if x > 0. nan is returned for nan inputs.\n",
    "\n",
    "def minimo_bl (vector):\n",
    "    data = np.asarray(vector,dtype=np.int)\n",
    "    b = (np.diff(np.sign(np.diff(data))) > 0).nonzero()[0] + 1\n",
    "    return b\n",
    "\n",
    "# Esta celda calcula los mínimos de la selección de toda la célula tomando los mínimos calculados, quedandose con el más chico entre dos máximos.\n",
    "# Devuelve el valor de tiempos y las intensidades en dataframes por separado.\n",
    "\n",
    "sparks_tiempo0 = []\n",
    "sparks_intensidad0 = []        \n",
    "sparks_tiempo_n = []\n",
    "sparks_intensidad_n = []\n",
    "\n",
    "for i in range (0,cantidad_sparks):\n",
    "    picos = minimo_bl (list_img_col[i])\n",
    "    lista_min = []\n",
    "    for minimo in picos:\n",
    "        picomenor = int(out_sparks['tiempo_maximo'][i])\n",
    "        if minimo < picomenor:\n",
    "            y_min = list_img_col[i] [minimo]\n",
    "            lista_min.append((minimo,y_min))\n",
    "    try:\n",
    "        minimo_lista_mins = min(lista_min, key = lambda t: t[1])\n",
    "        sparks_tiempo0.append(minimo_lista_mins[0])\n",
    "        sparks_intensidad0.append (minimo_lista_mins[1])\n",
    "    except ValueError:\n",
    "        minimo_lista_mins = min (list_img_col[i][0:int(out_sparks['tiempo_maximo'][i])])\n",
    "        minimimo = list_img_col[i].index(minimo_lista_mins)\n",
    "        sparks_tiempo0.append(minimimo)\n",
    "        sparks_intensidad0.append (minimo_lista_mins)\n",
    "\n",
    "out_sparks['tiempo_minimo'] = sparks_tiempo0\n",
    "out_sparks['intensidad_minima'] = sparks_intensidad0\n",
    "\n",
    "# final minimun\n",
    "\n",
    "for i in range (0,cantidad_sparks):\n",
    "    picos = minimo_bl (list_img_col[i])\n",
    "    lista_min = []\n",
    "    for minimo in picos:\n",
    "        picomenor = int(out_sparks['tiempo_maximo'][i])\n",
    "        if minimo > picomenor:\n",
    "            y_min = list_img_col[i] [minimo]\n",
    "            lista_min.append((minimo,y_min))\n",
    "    try:\n",
    "        minimo_lista_mins = min(lista_min, key = lambda t: t[1])\n",
    "        sparks_tiempo_n.append(minimo_lista_mins[0])\n",
    "        sparks_intensidad_n.append (minimo_lista_mins[1])\n",
    "    except ValueError:\n",
    "        minimo_lista_mins = min (list_img_col[i][int(out_sparks['tiempo_maximo'][i]):len (list_img_col[i])])\n",
    "        minimimo = list_img_col[i].index(minimo_lista_mins)\n",
    "        sparks_tiempo_n.append(minimimo)\n",
    "        sparks_intensidad_n.append (minimo_lista_mins)\n",
    "\n",
    "out_sparks['tiempo_valle'] = sparks_tiempo_n\n",
    "out_sparks['intensidad_valle'] = sparks_intensidad_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula la amplitud de cada pico como la diferencia entre la intensidad máximo y mínimo \n",
    "\n",
    "sparks_amplitud = []\n",
    "for sp in range(0, cantidad_sparks):\n",
    "    sp_amplitud = (out_sparks['intensidad_maxima'] [sp] - out_sparks['intensidad_minima'] [sp])/out_sparks['intensidad_minima'] [sp]\n",
    "    sparks_amplitud.append(sp_amplitud)\n",
    "out_sparks['amplitud'] = sparks_amplitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo del tiempo al pico como la diferencia en el tiempo máximo y mínimo para toda la selección\n",
    "\n",
    "sparks_tiempo_al_pico = []\n",
    "for sp in range  (0, cantidad_sparks):\n",
    "    sp_ttp = out_sparks['tiempo_maximo'] [sp] - out_sparks['tiempo_minimo'] [sp]\n",
    "    sparks_tiempo_al_pico.append(sp_ttp)\n",
    "out_sparks['TTP'] = sparks_tiempo_al_pico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leand\\PyMOL\\lib\\site-packages\\ipykernel_launcher.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# Calcula el tiempo al 50% del pico de cada pico de la selección\n",
    "\n",
    "sparks_tiempo_pico50 = []\n",
    "\n",
    "for sp in range  (0, cantidad_sparks):\n",
    "    sp_amp50 = (out_sparks['intensidad_maxima'] [sp] + out_sparks['intensidad_minima'] [sp])/2   \n",
    "    x1 = np.asarray (range (int(out_sparks['tiempo_minimo'] [sp]), int(out_sparks['tiempo_maximo'] [sp]+1))) \n",
    "    y1 = np.asarray (list_img_col [sp] [int(out_sparks['tiempo_minimo'] [sp]) : int(out_sparks['tiempo_maximo'] [sp]+1)])\n",
    "    ySS = 0\n",
    "    (amplitudeEst,tauEst) = sparks_analysis.fitExponent(x1,y1,ySS)\n",
    "    yEst = amplitudeEst*(exp(-x1/tauEst))+ySS\n",
    "    sp_ttp50 = (np.log((sp_amp50 -ySS)/ amplitudeEst))*(-tauEst)\n",
    "    sparks_tiempo_pico50.append (sp_ttp50)\n",
    "out_sparks['TTP50'] = sparks_tiempo_pico50 - out_sparks['tiempo_minimo']\n",
    "\n",
    "# Calculo del FDHM\n",
    "sparks_tiempo_pico50_2 = []\n",
    "for sp in range  (0, cantidad_sparks):\n",
    "    sp_amp50 = (out_sparks['intensidad_maxima'] [sp] + out_sparks['intensidad_minima'] [sp])/2\n",
    "    x2 = np.asarray (range (int(out_sparks['tiempo_maximo'] [sp]), int(out_sparks['tiempo_valle'] [sp]+1))) \n",
    "    y2 = np.asarray (list_img_col [sp] [int(out_sparks['tiempo_maximo'] [sp]) : int(out_sparks['tiempo_valle'] [sp]+1)])\n",
    "    (amplitudeEst2,tauEst2) = sparks_analysis.fitExponent(x2,y2,ySS)  \n",
    "    yEst2 = amplitudeEst2*(exp(-x2/tauEst2))+ySS\n",
    "    sp_ttp50_2 = (np.log((sp_amp50 -ySS)/ amplitudeEst2))*(-tauEst2)\n",
    "    sparks_tiempo_pico50_2.append (sp_ttp50_2)\n",
    "out_sparks['FDHM'] =[A - B for (A, B) in zip(sparks_tiempo_pico50_2, sparks_tiempo_pico50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leand\\PyMOL\\lib\\site-packages\\ipykernel_launcher.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "# Aplico la función para tau a la selección\n",
    "\n",
    "sp_tau = []\n",
    "for sp in range (0, cantidad_sparks):\n",
    "    x = np.asarray(list (range(int(out_sparks['tiempo_maximo'] [sp]), int(out_sparks['tiempo_valle'] [sp])+1))) #* x_calibracion\n",
    "    y = np.asarray(list_img_col[sp][int(out_sparks['tiempo_maximo'] [sp]) : int(out_sparks['tiempo_valle'] [sp])+1],dtype=np.float64)\n",
    "    ySS = 0\n",
    "    (amplitudeEst,tauEst) = sparks_analysis.fitExponent(x,y,ySS)\n",
    "    yEst = amplitudeEst*(exp(-x/tauEst))+ySS\n",
    "    sp_tau.append (tauEst)\n",
    "\n",
    "out_sparks['tau'] = sp_tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Calculo de (ΔF/F0)/ΔTmax\n",
    "\n",
    "out_sparks['(ΔF/F0)/ΔTmax'] = out_sparks['amplitud']/out_sparks['TTP']\n",
    "\n",
    "##  Calculo fullDuration\n",
    "\n",
    "out_sparks['fullDuration'] = out_sparks['tiempo_valle'] - out_sparks['tiempo_minimo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate thorugh contours and filter for ROI para el ancho de pico\n",
    "list_img_row = []\n",
    "track_number = 0\n",
    "for c in cnts:\n",
    "    img_row_mean = sparks_analysis.track_contours (c, auto_result, track_number) [1]\n",
    "    track_number +=1\n",
    "    list_img_row.append (img_row_mean)\n",
    "\n",
    "sparks_analysis.display_image ('image' , auto_result)\n",
    "\n",
    "def maximo_peak (vector):\n",
    "    import numpy as np\n",
    "    from peakutils.peak import indexes\n",
    "    import peakutils\n",
    "    indexes = indexes(np.array(vector), thres=1.0/max(vector), min_dist=10)\n",
    "    kk = list(indexes)\n",
    "    for j in kk:\n",
    "        if vector[j]> (sum(vector) / len(vector)):\n",
    "            tiempos = j\n",
    "            intensidades = vector[j]\n",
    "    return tiempos,intensidades\n",
    "\n",
    "cantidad_sparks = len(list_img_row)\n",
    "\n",
    "datos_tiempos = {}\n",
    "datos_intensidades = {}\n",
    "\n",
    "for i in range (0,cantidad_sparks):\n",
    "    picos = maximo_peak (list_img_row[i])\n",
    "    datos_tiempos [i] = picos [0]\n",
    "    datos_intensidades [i] = picos [1]\n",
    "    \n",
    "\n",
    "Columns = ['Spark_'+ str(x) for x in range(0, cantidad_sparks)]\n",
    "out_sparks_row = pd.DataFrame([datos_tiempos.values(),datos_intensidades.values()], columns = Columns).T\n",
    "out_sparks_row = pd.DataFrame(out_sparks_row.values, columns = ['tiempo_maximo', 'intensidad_maxima'])\n",
    "\n",
    "# Esta celda calcula los mínimos de la selección de toda la célula tomando los mínimos calculados, quedandose con el más chico entre dos máximos.\n",
    "# Devuelve el valor de tiempos y las intensidades en dataframes por separado.\n",
    "\n",
    "sparks_tiempo0 = []\n",
    "sparks_intensidad0 = []        \n",
    "sparks_tiempo_n = []\n",
    "sparks_intensidad_n = []\n",
    "\n",
    "for i in range (0,cantidad_sparks):\n",
    "    picos = minimo_bl (list_img_row[i])\n",
    "    lista_min = []\n",
    "    for minimo in picos:\n",
    "        picomenor = int(out_sparks_row['tiempo_maximo'][i])\n",
    "        if minimo < picomenor:\n",
    "            y_min = list_img_row[i] [minimo]\n",
    "            lista_min.append((minimo,y_min))\n",
    "    try:\n",
    "        minimo_lista_mins = min(lista_min, key = lambda t: t[1])\n",
    "        sparks_tiempo0.append(minimo_lista_mins[0])\n",
    "        sparks_intensidad0.append (minimo_lista_mins[1])\n",
    "    except ValueError:\n",
    "        minimo_lista_mins = min (list_img_row[i][0:int(out_sparks['tiempo_maximo'][i])])\n",
    "        minimimo = list_img_row[i].index(minimo_lista_mins)\n",
    "        sparks_tiempo0.append(minimimo)\n",
    "        sparks_intensidad0.append (minimo_lista_mins)\n",
    "\n",
    "out_sparks_row['tiempo_minimo'] = sparks_tiempo0\n",
    "out_sparks_row['intensidad_minima'] = sparks_intensidad0\n",
    "\n",
    "# final minimun\n",
    "\n",
    "for i in range (0,cantidad_sparks):\n",
    "    picos = minimo_bl (list_img_row[i])\n",
    "    lista_min = []\n",
    "    for minimo in picos:\n",
    "        picomenor = int(out_sparks['tiempo_maximo'][i])\n",
    "        if minimo > picomenor:\n",
    "            y_min = list_img_row[i] [minimo]\n",
    "            lista_min.append((minimo,y_min))\n",
    "    try:\n",
    "        minimo_lista_mins = min(lista_min, key = lambda t: t[1])\n",
    "        sparks_tiempo_n.append(minimo_lista_mins[0])\n",
    "        sparks_intensidad_n.append (minimo_lista_mins[1])\n",
    "    except ValueError:\n",
    "        minimo_lista_mins = min (list_img_row[i][int(out_sparks['tiempo_maximo'][i]):len (list_img_row[i])])\n",
    "        minimimo = list_img_row[i].index(minimo_lista_mins)\n",
    "        sparks_tiempo_n.append(minimimo)\n",
    "        sparks_intensidad_n.append (minimo_lista_mins)\n",
    "\n",
    "out_sparks_row['tiempo_valle'] = sparks_tiempo_n\n",
    "out_sparks_row['intensidad_valle'] = sparks_intensidad_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Calculo fullWidth\n",
    "\n",
    "out_sparks['fullWidth'] = out_sparks_row['tiempo_valle'] - out_sparks_row['tiempo_minimo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "3 3\n",
      "4 4\n",
      "3 3\n",
      "5 5\n",
      "2 2\n",
      "6 6\n",
      "8 8\n",
      "14 14\n",
      "4 4\n",
      "12 12\n",
      "3 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leand\\PyMOL\\lib\\site-packages\\ipykernel_launcher.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# Calculo del FWHM\n",
    "\n",
    "sparks_tiempo_pico50 = []\n",
    "\n",
    "for sp in range  (0, cantidad_sparks):\n",
    "    sp_amp50 = (out_sparks_row['intensidad_maxima'] [sp] + out_sparks_row['intensidad_minima'] [sp])/2   \n",
    "    x1 = np.asarray (range (int(out_sparks_row['tiempo_minimo'] [sp]), int(out_sparks_row['tiempo_maximo'] [sp]+1))) \n",
    "    y1 = np.asarray (list_img_row [sp] [int(out_sparks_row['tiempo_minimo'] [sp]) : int(out_sparks_row['tiempo_maximo'] [sp]+1)])\n",
    "    ySS = 0\n",
    "    (amplitudeEst,tauEst) = sparks_analysis.fitExponent(x1,y1,ySS)\n",
    "    yEst = amplitudeEst*(exp(-x1/tauEst))+ySS\n",
    "    sp_ttp50 = (np.log((sp_amp50 -ySS)/ amplitudeEst))*(-tauEst)\n",
    "    sparks_tiempo_pico50.append (sp_ttp50)\n",
    "out_sparks_row['TTP50'] = sparks_tiempo_pico50 - out_sparks_row['tiempo_minimo']\n",
    "\n",
    "\n",
    "sparks_tiempo_pico50_2 = []\n",
    "for sp in range  (0, cantidad_sparks):\n",
    "    sp_amp50 = (out_sparks_row['intensidad_maxima'] [sp] + out_sparks_row['intensidad_minima'] [sp])/2\n",
    "    x2 = np.asarray (range (int(out_sparks_row['tiempo_maximo'] [sp]), int(out_sparks_row['tiempo_valle'] [sp]+1))) \n",
    "    y2 = np.asarray (list_img_row [sp] [int(out_sparks_row['tiempo_maximo'] [sp]) : int(out_sparks_row['tiempo_valle'] [sp]+1)])\n",
    "    (amplitudeEst2,tauEst2) = sparks_analysis.fitExponent(x2,y2,ySS)  \n",
    "    yEst2 = amplitudeEst2*(exp(-x2/tauEst2))+ySS\n",
    "    sp_ttp50_2 = (np.log((sp_amp50 -ySS)/ amplitudeEst2))*(-tauEst2)\n",
    "    sparks_tiempo_pico50_2.append (sp_ttp50_2)\n",
    "out_sparks['FWHM'] =[A - B for (A, B) in zip(sparks_tiempo_pico50_2, sparks_tiempo_pico50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tiempo_maximo</th>\n",
       "      <th>intensidad_maxima</th>\n",
       "      <th>tiempo_minimo</th>\n",
       "      <th>intensidad_minima</th>\n",
       "      <th>tiempo_valle</th>\n",
       "      <th>intensidad_valle</th>\n",
       "      <th>TTP50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>138.363636</td>\n",
       "      <td>2</td>\n",
       "      <td>82.909091</td>\n",
       "      <td>15</td>\n",
       "      <td>81.272727</td>\n",
       "      <td>2.178061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>136.222222</td>\n",
       "      <td>1</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>112.888889</td>\n",
       "      <td>2.312120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>150.944444</td>\n",
       "      <td>3</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>101.055556</td>\n",
       "      <td>2.875881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>155.846154</td>\n",
       "      <td>2</td>\n",
       "      <td>101.769231</td>\n",
       "      <td>7</td>\n",
       "      <td>109.923077</td>\n",
       "      <td>1.895327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>121.384615</td>\n",
       "      <td>0</td>\n",
       "      <td>78.461538</td>\n",
       "      <td>9</td>\n",
       "      <td>71.769231</td>\n",
       "      <td>3.238165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>152.153846</td>\n",
       "      <td>2</td>\n",
       "      <td>81.307692</td>\n",
       "      <td>11</td>\n",
       "      <td>121.076923</td>\n",
       "      <td>3.675918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>167.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>83.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>108.666667</td>\n",
       "      <td>3.196722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>173.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>87.222222</td>\n",
       "      <td>14</td>\n",
       "      <td>65.888889</td>\n",
       "      <td>2.969145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>72.181818</td>\n",
       "      <td>21</td>\n",
       "      <td>67.954545</td>\n",
       "      <td>4.643545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.0</td>\n",
       "      <td>163.850000</td>\n",
       "      <td>7</td>\n",
       "      <td>133.250000</td>\n",
       "      <td>14</td>\n",
       "      <td>115.800000</td>\n",
       "      <td>1.384518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.0</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>98.083333</td>\n",
       "      <td>15</td>\n",
       "      <td>70.916667</td>\n",
       "      <td>2.964840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.0</td>\n",
       "      <td>140.555556</td>\n",
       "      <td>1</td>\n",
       "      <td>73.333333</td>\n",
       "      <td>8</td>\n",
       "      <td>83.333333</td>\n",
       "      <td>2.005901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tiempo_maximo  intensidad_maxima  tiempo_minimo  intensidad_minima  \\\n",
       "0             6.0         138.363636              2          82.909091   \n",
       "1             5.0         136.222222              1          92.000000   \n",
       "2             9.0         150.944444              3          82.000000   \n",
       "3             5.0         155.846154              2         101.769231   \n",
       "4             5.0         121.384615              0          78.461538   \n",
       "5            10.0         152.153846              2          81.307692   \n",
       "6             7.0         167.833333              1          83.750000   \n",
       "7             7.0         173.666667              2          87.222222   \n",
       "8             8.0         136.500000              1          72.181818   \n",
       "9            11.0         163.850000              7         133.250000   \n",
       "10            4.0         170.000000              0          98.083333   \n",
       "11            6.0         140.555556              1          73.333333   \n",
       "\n",
       "    tiempo_valle  intensidad_valle     TTP50  \n",
       "0             15         81.272727  2.178061  \n",
       "1              7        112.888889  2.312120  \n",
       "2             12        101.055556  2.875881  \n",
       "3              7        109.923077  1.895327  \n",
       "4              9         71.769231  3.238165  \n",
       "5             11        121.076923  3.675918  \n",
       "6             12        108.666667  3.196722  \n",
       "7             14         65.888889  2.969145  \n",
       "8             21         67.954545  4.643545  \n",
       "9             14        115.800000  1.384518  \n",
       "10            15         70.916667  2.964840  \n",
       "11             8         83.333333  2.005901  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sparks_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
