{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jasonReader(path):\n",
    "    \"\"\" Reads the .jason generated with jasonGenartor the given path\"\"\"\n",
    "    with open(path,'r') as miarch:\n",
    "        loaded_dict = json.loads(miarch.read())\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_amplitudes(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['amplitudes']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['amplitudes']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/analisis/'\n",
    "path = '/media/leandro/Volumen1TB/Lean/Analizador_imagenes_calcio/Luis/analisis/'\n",
    "experiments = os.listdir(path + 'jsons/')\n",
    "dif_amp = pd.DataFrame()\n",
    "for i in range(0,len (experiments)):\n",
    "    experiment = jasonReader(path + 'jsons/' + experiments[i]) \n",
    "    try:\n",
    "        amp_file = slicesParser_amplitudes(experiment)\n",
    "    except:\n",
    "        print(experiments[i])\n",
    "    try:\n",
    "        dif_amp [i]= experiments[i],(amp_file['transient1'] - amp_file['transient2']).mean()\n",
    "    except:\n",
    "        pass\n",
    "dif_amp = pd.DataFrame (dif_amp.T)\n",
    "dif_amp.columns = ['file','dif_amp_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.read_csv('/media/leandro/Volumen1TB/Lean/Analizador_imagenes_calcio/Luis/seleccion/tabulado_imagenes.csv', encoding='utf-8')\n",
    "del tab['Unnamed: 0']\n",
    "pd.set_option('display.max_rows', None)\n",
    "controles = tab[tab['tratamiento'] == 'c']\n",
    "controles = controles.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = os.listdir(path + 'jsons/')\n",
    "experiments = []\n",
    "for j in range(0,len(exps)):\n",
    "    for i in range(0,len(controles)):\n",
    "        if str(controles['experimento'][i]) in exps[j]:\n",
    "            if str(controles['foto'][i]) in exps[j]:\n",
    "                experiments.append(exps[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-76-6d31658230a6>:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  amp_files.loc[len(amp_files)+1] = [amp_files['transient1'][len(amp_files)]*100/amp_files['transient_max'][len(amp_files)],amp_files['transient2'][len(amp_files)]*100/amp_files['transient_max'][len(amp_files)],'']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "060121_analysis_result_c9d000.json\n"
     ]
    }
   ],
   "source": [
    "path = '/media/leandro/Volumen1TB/Lean/Analizador_imagenes_calcio/Luis/analisis/'\n",
    "# experiments = os.listdir(path + 'jsons/')\n",
    "complete_file = pd.DataFrame()\n",
    "for i in range(0,len (experiments)):\n",
    "    try:\n",
    "        experiment = jasonReader(path + 'jsons/' + experiments[i])\n",
    "        amp_files = slicesParser_amplitudes(experiment).filter(['transient1','transient2'])\n",
    "        amp_files = amp_files[:][0:33]\n",
    "        transient_max = []\n",
    "        for j in range(1,len(amp_files)+1):\n",
    "            transient_max.append(max(amp_files['transient1'][j],amp_files['transient2'][j]))\n",
    "        amp_files['transient_max'] = transient_max\n",
    "        amp_files.loc[len(amp_files)+1] = (amp_files.mean())\n",
    "        amp_files.loc[len(amp_files)+1] = [amp_files['transient1'][len(amp_files)]*100/amp_files['transient_max'][len(amp_files)],amp_files['transient2'][len(amp_files)]*100/amp_files['transient_max'][len(amp_files)],'']\n",
    "        amp_files[str(experiments[i])] = list(range(1,len(amp_files)-1))+['promedios']+['porcentaje_max']\n",
    "        complete_file = pd.concat([complete_file,amp_files], axis=1)\n",
    "    except ValueError:\n",
    "        print(experiments[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_file.to_excel(path + 'DICRI_controles.xlsx', engine='xlsxwriter')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amplitud de transitorio global vs DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/leandro/Volumen1TB/Lean/Analizador_imagenes_calcio/Luis/analisis/json_nuevos/'\n",
    "file_tabulado = pd.read_csv(path + 'tabulado_parceado.csv')\n",
    "file_tabulado.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = jasonReader(path + 'jsons/050320c8_analysis_result_8b000.json')\n",
    "allSlices = experiment['slices']\n",
    "for i in range(0,len(allSlices)):\n",
    "    print(allSlices[i]['amplitudes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/leandro/Volumen1TB/Lean/Analizador_imagenes_calcio/Luis/analisis/json_nuevos/whole_cell/'\n",
    "experiments = os.listdir(path)\n",
    "df = pd.DataFrame()\n",
    "for experiment in experiments:\n",
    "    df = pd.read_csv(path + experiment, sep = '\\t', index_col=0).loc['amplitudes']\n",
    "    for imagen in range(0,len(file_tabulado)):\n",
    "        cel = file_tabulado['c√©lula'].loc[imagen]\n",
    "        foto = file_tabulado['foto'].loc[imagen]\n",
    "        if (cel in experiment) & (foto in experiment):\n",
    "            print(experiment,df)\n",
    "\n",
    "#     print (experiment, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALBUMINA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python code demonstrate creating  \n",
    "# DataFrame from dict narray / lists  \n",
    "# By default addresses. \n",
    "  \n",
    "import pandas as pd \n",
    "  \n",
    "# intialise data of lists. \n",
    "data = {'BSA':[102, 97, 79], \n",
    "        'HSA':[65, 74, 69.5],\n",
    "        'RabSA':[57, 63.3, 70],\n",
    "        'RSA':[50, 51, 52],\n",
    "        'PSA':[45, 48, 55]} \n",
    "  \n",
    "# Create DataFrame \n",
    "df = pd.DataFrame(data)\n",
    "df_mean = df.mean()\n",
    "df_std = df.std()\n",
    "# Print the output. \n",
    "df_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.errorbar(df_mean.index, df_mean, yerr=df_std, xerr=None, fmt='o')\n",
    "plt.ylabel('% convertion', fontdict=None, labelpad=None,loc=None)\n",
    "plt.savefig('/media/leandro/Volumen1TB/Lean/Albumina/%alb_convertion.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambios_fq = pd.read_csv('/media/leandro/Volumen1TB/Lean/Albumina/cambios_fq_completos.csv', sep= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cambios_fq.loc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
