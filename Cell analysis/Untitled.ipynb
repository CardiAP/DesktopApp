{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a52eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '/media/leandro/Volumen1TB1/Alt Atlas/Image_analysis')\n",
    "\n",
    "import src.Upload_images as ui\n",
    "import src.Filtering as F\n",
    "import src.Data_extraction as de\n",
    "import src.Data_processing as dp\n",
    "import src.plotting_visualization as pv\n",
    "import src.ROI_manual_selector as rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6263307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaborfilter():\n",
    "    # This function is designed to produce a set of GaborFilters \n",
    "    # an even distribution of theta values equally distributed amongst pi rad / 180 degree\n",
    "     \n",
    "    filters = []\n",
    "    num_filters = 64\n",
    "    ksize = 3  # The local area to evaluate\n",
    "    sigma = 5.0  # Larger Values produce more edges\n",
    "    lambd = 10.0\n",
    "    gamma = 0.5\n",
    "    psi = 0  # Offset value - lower generates cleaner results\n",
    "    for theta in np.arange(0, np.pi, np.pi / num_filters):  # Theta is the orientation for edge detection\n",
    "        kern = cv2.getGaborKernel((ksize, ksize), sigma, theta, lambd, gamma, psi, ktype=cv2.CV_64F)\n",
    "        kern /= 1.0 * kern.sum()  # Brightness normalization\n",
    "        filters.append(kern)\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filter(img, filters):\n",
    "# This general function is designed to apply filters to our image\n",
    "     \n",
    "    # First create a numpy array the same size as our input image\n",
    "    newimage = np.zeros_like(img)\n",
    "     \n",
    "    # Starting with a blank image, we loop through the images and apply our Gabor Filter\n",
    "    # On each iteration, we take the highest value (super impose), until we have the max value across all filters\n",
    "    # The final image is returned\n",
    "    depth = -1 # remain depth same as original image\n",
    "     \n",
    "    for kern in filters:  # Loop through the kernels in our GaborFilter\n",
    "        image_filter = cv2.filter2D(img, depth, kern)  #Apply filter to image\n",
    "         \n",
    "        # Using Numpy.maximum to compare our filter and cumulative image, taking the higher value (max)\n",
    "        np.maximum(newimage, image_filter, newimage)\n",
    "    return newimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91af822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "#The line below is necessary to show Matplotlib's plots inside a Jupyter Notebook\n",
    "%matplotlib inline\n",
    " \n",
    "from matplotlib import pyplot as plt\n",
    " \n",
    "#Use this helper function if you are working in Jupyter Lab\n",
    "#If not, then directly use cv2.imshow(<window name>, <image>)\n",
    " \n",
    "def showimage(myimage, figsize=[10,10]):\n",
    "    if (myimage.ndim>2):  #This only applies to RGB or RGBA images (e.g. not to Black and White images)\n",
    "        myimage = myimage[:,:,::-1] #OpenCV follows BGR order, while matplotlib likely follows RGB order\n",
    "         \n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(myimage, cmap = 'gray', interpolation = 'bicubic')\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06553376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create our gabor filters, and then apply them to our image\n",
    "gfilters = create_gaborfilter()\n",
    "image_g = apply_filter(image2, gfilters)\n",
    " \n",
    "showimage(image_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b947cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/media/leandro/Volumen1TB1/Alt Atlas/images/Human Embryonic Stem Cells and Human Induced Pluripotent Stem Cell Images/Cells/'\n",
    "arr = os.listdir(path)\n",
    "for photo in arr:\n",
    "    img = ui.readimages_asmatrix(path + photo)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize (img,(750,500), interpolation = cv2.INTER_AREA)\n",
    "    mask = dp.binary_mask(img,0.1,k_size=3,iterations=2)\n",
    "    n_white_pix = np.sum(mask == 255)\n",
    "    print('% of cells area:', photo, n_white_pix*100/mask.size)\n",
    "    filtered = F.image_filtration (mask, 5, 75)\n",
    "#         pv.display_image(filtered, photo)\n",
    "    contours = de.find_contours(filtered) # Obtains elements by contours\n",
    "    print(len(contours))\n",
    "    area = []\n",
    "    for i in range(len(contours)):\n",
    "        area.append(cv2.contourArea(contours[i]))\n",
    "        ratio = 4 * np.pi * cv2.contourArea(contours[i]) / (cv2.arcLength(contours[i],True)**2 )\n",
    "        print(ratio)\n",
    "    print(photo,sum(area))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(photo)\n",
    "    plt.imshow(cv2.drawContours(mask, contours, -1, (0,255,0), 3))\n",
    "#     fig1 = plt.figure()\n",
    "#     plt.hist(img.ravel(),256,[0,256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1dea81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/lean/Documentos/Lean/Alt Atlas/Photos/PRIMARY CELL WHARTON_S JELLY MSC  IMAGES FROM HUMAN-PREVIOUS WORK OF DR. SENEM SIMSEK/'\n",
    "arr = os.listdir(path)\n",
    "for photo in arr:\n",
    "    img = cv2.imread(path + photo)\n",
    "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#     gray = cv2.resize (gray,(750,500), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # Threshold for mask\n",
    "    # Dealing with sub figures...\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    gray_1D = gray.ravel()<250 \n",
    "    gray1D_filtered = gray.ravel()[gray_1D]\n",
    "\n",
    "    \n",
    "    threshold = np.quantile(gray1D_filtered,0.23)\n",
    "    max_value = np.quantile(gray1D_filtered,0.95)\n",
    "    print(threshold,max_value)\n",
    "    _, mask = cv2.threshold(gray, thresh=160, maxval=max_value, type=cv2.THRESH_BINARY)\n",
    "\n",
    "    # The kernel to be used for dilation purpose\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    Mask = cv2.erode(mask, kernel)\n",
    "#     Mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    # Inverting the mask by\n",
    "    # performing bitwise-not operation\n",
    "    Mask = cv2.bitwise_not(Mask)\n",
    "    # Printing % of cells area\n",
    "    n_white_pix = np.sum(Mask == 255)\n",
    "    print('% of cells area:', photo, n_white_pix*100/Mask.size)\n",
    "    \n",
    "    # Displaying the image\n",
    "    plt.imshow(Mask,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87ac7dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/media/leandro/Volumen1TB1/Lean/Patricio Sobrero/'\n",
    "img = cv2.imread(path + '6_CHA0_NYB_4.tif')\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize (img,(750,500), interpolation = cv2.INTER_AREA)\n",
    "mask = dp.binary_mask(img,0.1,k_size=3,iterations=2)\n",
    "filtered = F.image_filtration (mask, 3, 70)\n",
    "contours = de.find_contours(filtered) # Obtains elements by contours\n",
    "print(len(contours))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(photo)\n",
    "plt.imshow(256-mask,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db631cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3)\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(15)\n",
    "plt.title('dif')\n",
    "axs[0].imshow(image1,cmap='gray', vmin=0, vmax=255)\n",
    "axs[1].imshow(image2,cmap='gray', vmin=0, vmax=255)\n",
    "axs[2].imshow(image1+image2,cmap='gray', vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633111c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1+image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3267b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in np.arange (2, 11):\n",
    "    print (i)\n",
    "    mask = cv2.Canny(255-image1+image2, 10, i*10, 100)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "#     mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    contours = de.find_contours(mask) # Obtains elements by contours\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.title(len(contours))\n",
    "    plt.imshow(mask,cmap='gray')\n",
    "#     plt.imshow(cv2.drawContours(mask, contours, 1, (0,255,0), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.drawContours(img, contours, -1, (0,255,0), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a31db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "target = cv2.imread('/media/leandro/Volumen1TB1/Alt Atlas/images/Human Embryonic Stem Cells and Human Induced Pluripotent Stem Cell Images/Cells/Project_Image001 NC_UCMSC_P5_SS High Glucose.jpg' , cv2.IMREAD_COLOR)\n",
    "img = cv2.cvtColor(target,cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.resize (img,(750,500), interpolation = cv2.INTER_AREA)\n",
    "mask = dp.binary_mask(img,0.1,k_size=3,iterations=2)\n",
    "SearchImage = cv2.bitwise_and(target,target,mask = mask)\n",
    "\n",
    "# cv2.imshow(\"Search Region\" , SearchImage)\n",
    "# cv2.waitKey()\n",
    "\n",
    "#convert RGBto Lab\n",
    "LabImage = cv2.cvtColor(SearchImage,cv2.COLOR_BGR2LAB)\n",
    "\n",
    "# cv2.imshow(\"Lab(b)\" , LabImage[:, :, 1])\n",
    "# cv2.waitKey()\n",
    "\n",
    "ret,Binary = cv2.threshold(LabImage[:, :, 1], 0, 255, cv2.THRESH_OTSU)\n",
    "# cv2.imshow('win1', Binary)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    " #find contours\n",
    "contours, hierarchy = cv2.findContours(Binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#create an empty image for contours\n",
    "img_contours = np.zeros(target.shape)\n",
    "# draw the contours on the empty image\n",
    "cv2.drawContours(img_contours, contours, -1, (0,255,0), 3)\n",
    "\n",
    "for cnt in contours:\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = float(w) / h\n",
    "\n",
    "    area = cv2.contourArea(cnt)\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    rect_area = w * h\n",
    "    extent = float(area) / rect_area\n",
    "\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    solidity = float(area) / hull_area\n",
    "\n",
    "    equi_diameter = np.sqrt(4 * area / np.pi)\n",
    "\n",
    "    (x, y), (MA, ma), Orientation = cv2.fitEllipse(cnt)\n",
    "\n",
    "    print(\" Width = {}  Height = {} area = {}  aspect ration = {}  extent  = {}  solidity = {}   equi_diameter = {}   orientation = {}\".format(  w , h , area , \n",
    "    aspect_ratio , extent , solidity , equi_diameter , Orientation))\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow('win1', img_contours)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb52ea1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = ui.readimages_asmatrix(path + 'Project_Image001 NC_UCMSC_P5_SS High Glucose.jpg')\n",
    "image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "contours = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "area_thresh1 = 500\n",
    "area_thresh2 = 1000\n",
    "aspect_thresh1 = 2\n",
    "aspect_thresh2 = 4\n",
    "result1 = image.copy()\n",
    "result2 = image.copy()\n",
    "for c in contours:\n",
    "\n",
    "    # get rotated rectangle from contour\n",
    "    # get its dimensions\n",
    "    # get angle relative to horizontal from rotated rectangle\n",
    "#     rotrect = cv2.minAreaRect(c)\n",
    "    box = cv2.boxPoints(c)\n",
    "    box = np.int0(box)\n",
    "    (center), (dim1,dim2), angle = rotrect\n",
    "    maxdim = max(dim1,dim2)\n",
    "    mindim = min(dim1,dim2)\n",
    "    area = dim1 * dim2\n",
    "    if area > 0:\n",
    "        aspect = maxdim / mindim\n",
    "        #print(area, aspect)\n",
    "\n",
    "    if (area > area_thresh1) and (area < area_thresh2) and (aspect > aspect_thresh1) and (aspect < aspect_thresh2):\n",
    "        # draw contour on input\n",
    "        cv2.drawContours(result1,[c],0,(255,255,255),1)\n",
    "        # draw rectangle on input\n",
    "        cv2.drawContours(result2,[box],0,(255,255,255),1)\n",
    "        print(area, aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc92b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = dp.binary_mask(imageBF3,0.65,k_size=3,iterations=2)\n",
    "# contours = de.find_contours(mask3) # Obtains elements by contours\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.title(len(contours))\n",
    "plt.imshow(mask3,cmap='gray')\n",
    "# cv2.imwrite('CHA0_NYB_mask.png',mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52871c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask3*imageBF3)\n",
    "# cv2.imwrite('CHA0_NYB_withmask.png',mask*image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = plt.hist((mask*imageGFP3).ravel(),256,[5,255])[2]\n",
    "# plt.savefig('CHA0_NYB_hist.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52069f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/leandro/Volumen1TB1/Lean/Patricio Sobrero/imagenes/'\n",
    "imageBF1 = cv2.imread(path + '191022_CHA0_1_BF.tif')[:,:,1]\n",
    "imageGFP1 = cv2.imread(path + '191022_CHA0_1_F.tif')[:,:,1]\n",
    "imageBF2 = cv2.imread(path + '191022_CHA0_2_BF.tif')[:,:,1]\n",
    "imageGFP2 = cv2.imread(path + '191022_CHA0_2_F.tif')[:,:,1]\n",
    "imageBF3 = cv2.imread(path + '191022_CHA0_3_BF.tif')[:,:,1]\n",
    "imageGFP3 = cv2.imread(path + '191022_CHA0_3_F.tif')[:,:,1]\n",
    "mask1 = dp.binary_mask(imageBF1,0.65,k_size=3,iterations=2)/255\n",
    "mask2 = dp.binary_mask(imageBF2,0.65,k_size=3,iterations=2)/255\n",
    "mask3 = dp.binary_mask(imageBF3,0.65,k_size=3,iterations=2)/255\n",
    "background_191022 = (mask1*imageGFP1).ravel()/(mask1*imageGFP1).ravel().mean() + (mask2*imageGFP2).ravel()/(mask2*imageGFP2).ravel().mean()# + (mask3*imageGFP3).ravel()/(mask3*imageGFP3).ravel().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b185248",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/media/leandro/Volumen1TB1/Lean/Patricio Sobrero/imagenes/'\n",
    "imageBF1 = cv2.imread(path + '201022_CHA0_1_BF.tif')[:,:,1]\n",
    "imageGFP1 = cv2.imread(path + '201022_CHA0_1_F.tif')[:,:,1]\n",
    "imageBF2 = cv2.imread(path + '201022_CHA0_2_BF.tif')[:,:,1]\n",
    "imageGFP2 = cv2.imread(path + '201022_CHA0_2_F.tif')[:,:,1]\n",
    "imageBF3 = cv2.imread(path + '201022_CHA0_3_BF.tif')[:,:,1]\n",
    "imageGFP3 = cv2.imread(path + '201022_CHA0_3_F.tif')[:,:,1]\n",
    "mask1 = dp.binary_mask(imageBF1,0.65,k_size=3,iterations=2)/255\n",
    "mask2 = dp.binary_mask(imageBF2,0.65,k_size=3,iterations=2)/255\n",
    "mask3 = dp.binary_mask(imageBF3,0.65,k_size=3,iterations=2)/255\n",
    "background_201022 = (mask1*imageGFP1).ravel()/(mask1*imageGFP1).ravel().mean() + (mask2*imageGFP2).ravel()/(mask2*imageGFP2).ravel().mean()# + (mask3*imageGFP3).ravel()/(mask3*imageGFP3).ravel().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d799ecb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ed475a55a375>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate the skewness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skew = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# Calculate the kurtosis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kurtosis = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkurtosis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data1' is not defined"
     ]
    }
   ],
   "source": [
    "# Importing library\n",
    "from scipy.stats import skew,kurtosis,variation\n",
    "\n",
    "# Calculate the skewness\n",
    "print('skew = ', skew(data1-data, axis=0, bias=True))\n",
    "# Calculate the kurtosis\n",
    "print('kurtosis = ', kurtosis(data1-data, axis=0, bias=True))\n",
    "print (\"Coefficient of Variation = \", variation(data1-data, axis = 0))\n",
    "with open(path+\"CHA0_PorfR2.txt\", \"w\") as text_file:\n",
    "    text_file.write('skew = '+ str(skew(data1-data, axis=0, bias=True))+'\\n'+\n",
    "                   'kurtosis = '+ str(kurtosis(data1-data, axis=0, bias=True))+'\\n'+\n",
    "                   \"Coefficient of Variation = \"+ str(variation(data1-data, axis = 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4466221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_vertical(image_matrix, pixel_start, pixel_end):\n",
    "    return image_matrix[pixel_start:pixel_end]\n",
    "\n",
    "\n",
    "def crop_horizontal(image_matrix, pixel_start, pixel_end):\n",
    "    return image_matrix[0:len(image_matrix), pixel_start:pixel_end]\n",
    "\n",
    "path = '/media/leandro/Volumen1TB1/Alt Atlas/images/Leloir/'\n",
    "# folder = os.listdir(path)\n",
    "# for photo in folder:\n",
    "#     if 'tif' in photo:\n",
    "photo = 'images.jpeg'\n",
    "if not os.path.exists(path + photo[:-4]):\n",
    "    os.makedirs(path + photo[:-4])\n",
    "image = ui.readimages_asmatrix(path+photo)\n",
    "image = cv2.resize(image, dsize=(250, 200), interpolation=cv2.INTER_CUBIC)\n",
    "for i in range (0,image.shape[1],50):\n",
    "    for j in range (0,image.shape[0],50):\n",
    "        image_data = crop_horizontal(image, i, i+50)\n",
    "        image_data = crop_vertical(image_data, j, j+50)\n",
    "        cv2.imwrite(path + photo[:-4]  + '/' + photo+str(i)+'_'+str(j)+'.jpg',image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fea80a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = '/media/leandro/Volumen1TB1/Lean/Patricio Sobrero/'\n",
    "\n",
    "dicc = {}\n",
    "for fecha in ['191022','201022']:\n",
    "    for cepa in ['CHA0','CHA19','CHA1009']:\n",
    "        for promotor in ['21910','PblbC','PofaA','PorfR1','PorfR2','PrsmZ']:\n",
    "            data_list = 0\n",
    "            for imagen in ['F','BF']:\n",
    "                for cel in range(1,4):\n",
    "                    try:\n",
    "                        image_name_GFP = fecha + '_' + cepa + '_' + promotor + '_' + str(cel) + '_' + 'F.tif'\n",
    "                        image_name_BF = str(fecha) + '_' + cepa + '_' + str(promotor) + '_' + str(cel) + '_' + 'BF.tif'\n",
    "                        imageGFP = cv2.imread(path + 'imagenes/' + image_name_GFP)[:,:,1]\n",
    "                        imageBF = cv2.imread(path + 'imagenes/' + image_name_BF)[:,:,1]\n",
    "                        mask = dp.binary_mask(imageBF,0.65,k_size=3,iterations=2)/255\n",
    "                        data_norm = (mask*imageGFP).ravel()/(mask*imageGFP).ravel().mean()\n",
    "                        data_list =+ data_norm\n",
    "                    except:\n",
    "                        pass\n",
    "            dicc[str(fecha) + '_' + str(cepa) + '_' + str(promotor)] = data_list \n",
    "df_exp = pd.DataFrame(dicc.items(), columns=['exp', 'array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d671a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "back_list = list(itertools.repeat(background_191022, 36))\n",
    "\n",
    "df_exp['background'] = back_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "555028ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp['array_norm'] = df_exp['array'] - df_exp['background']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f59034cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-97260d3107d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in df_exp['array_norm']:\n",
    "    for x in i:\n",
    "        while x < 1:\n",
    "            list(i).remove(x) \n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c20c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp.to_csv(path + 'CHA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48744e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "\n",
    "t = range(36)\n",
    "c = set(itertools.combinations(t, 2))\n",
    "c\n",
    "for combination in c:\n",
    "    print(df_exp['exp'][combination[0]],df_exp['exp'][combination[1]],ss.kstest(df_exp['array_norm'][combination[0]], df_exp['array_norm'][combination[1]], args=(), N=7077888, alternative='two-sided'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef89607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
