{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se puede probar la funcion de analisis de una imagen\n",
    "\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchonia_analysis\n",
    "import cv2\n",
    "\n",
    "# Path completo donde esta la imagen (incluyendo nombre y extencion)\n",
    "path = 'photos_examples/c1d000.tif'\n",
    "\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "ancho_corte = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 20\n",
    "\n",
    "image = cv2.imread(path)\n",
    "# Select ROI\n",
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "seleted_parameters = cv2.selectROI(image, fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image = image_data.get_image_data(image)\n",
    "image = image_data.crop_vertical(image, x_start, x_end)\n",
    "image = image_data.crop_horizontal(image, y_start, y_end)\n",
    "\n",
    "results = dyssynchonia_analysis.analyze_image(image, min_dist_between_maxs, ancho_corte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBA ANALISIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se puede probar la funcion de analisis todas las imagenes .tif en un directorio\n",
    "import os\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchonia_analysis\n",
    "import cv2\n",
    "\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "ancho_corte = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 20\n",
    "\n",
    "\n",
    "# Path donde estan las imagenes\n",
    "path = \"C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/seleccion/050320sel/050320c1\"\n",
    "\n",
    "images_paths = [ f'{path}/{file}' for file in os.listdir(path) if file.endswith(\".tif\") ]\n",
    "images = [ cv2.imread(image_path) for image_path in images_paths ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "\n",
    "#Tomamos la primer imagen para seleccionar el recorte elegido el resto de las imagenes se van a recortar igual\n",
    "seleted_parameters = cv2.selectROI(images[0], fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ image_data.get_image_data(image) for image in images ]\n",
    "images = [ image_data.crop_vertical(image, x_start, x_end) for image in images ]\n",
    "images = [ image_data.crop_horizontal(image, y_start, y_end) for image in images ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dy_analysis = [dyssynchonia_analysis.analyze_image(image, min_dist_between_maxs, ancho_corte) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + r'test.txt', 'w') as f:\n",
    "    f.write(\" \".join(map(str, dy_analysis)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de datos\n",
    "Notas: \n",
    "- Image corresponde al análisis de toda la célula y slices corresponde a fetas de esa imagen\n",
    "- intensidades es el valor que resulta de comprimir (sumando) la matriz con las coordenadas de x,y,z de los pixeles \n",
    "- max_peaks_pos es la index de en la lista de intensidades \n",
    "- max_peaks_intensities el valor de intensidad que se corresponde con el pico en la posicion analoga de max_peaks_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodes a dictionary into a jason\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def jasonGenerator(path,results):\n",
    "    \"\"\" Generates a .jason file in the path given folder from the a dictionary \"\"\"\n",
    "    with open(path + '/analysis_result.jason',\"w\") as miarch:\n",
    "        miarch.write(json.dumps(results, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jasonReader(path):\n",
    "    \"\"\" Reads the .jason generated with jasonGenartor the given path\"\"\"\n",
    "    with open( path + '/analysis_result.json','r') as miarch:\n",
    "        loaded_dict = json.loads(miarch.read())\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_max_peaksI(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    \n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x) for x in range(1,len(allSlices[0]['max_peaks_intensities']))]\n",
    "\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['max_peaks_intensities'][1:]\n",
    "\n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_halfpeakstime(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_half_peaks']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['times_to_half_peaks']\n",
    "\n",
    "        return df_sum\n",
    "\n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_amplitudes(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['amplitudes']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['amplitudes']\n",
    "\n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_min_peaksI(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['min_peaks_intensities']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['min_peaks_intensities']\n",
    "\n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_peaktime(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_peaks']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['times_to_peaks']\n",
    "\n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_tau(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    try:\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['tau_s']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['tau_s']\n",
    "        \n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible calculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicStasts(df):\n",
    "    if df.empty == False:\n",
    "        return df.astype('int').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discordIndex(df):\n",
    "    return df.iloc[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitudes_ratio(df):\n",
    "    df_alt = pd.DataFrame()\n",
    "    for i in range(0,len(list(df))-1):\n",
    "        name = 'ratio' + str(i+1) +'-' + str(i)\n",
    "        df_alt[name] = df[list(df)[i+1]]/df[list(df)[i]]\n",
    "    return df_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transient1</th>\n",
       "      <th>transient2</th>\n",
       "      <th>transient3</th>\n",
       "      <th>transient4</th>\n",
       "      <th>transient5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>47.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47.148936</td>\n",
       "      <td>47.468085</td>\n",
       "      <td>46.765957</td>\n",
       "      <td>47.042553</td>\n",
       "      <td>46.914894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.413393</td>\n",
       "      <td>2.619750</td>\n",
       "      <td>3.258519</td>\n",
       "      <td>3.368379</td>\n",
       "      <td>2.857711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>46.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       transient1  transient2  transient3  transient4  transient5\n",
       "count   47.000000   47.000000   47.000000   47.000000   47.000000\n",
       "mean    47.148936   47.468085   46.765957   47.042553   46.914894\n",
       "std      3.413393    2.619750    3.258519    3.368379    2.857711\n",
       "min     40.000000   42.000000   41.000000   39.000000   40.000000\n",
       "25%     45.000000   46.000000   45.000000   45.000000   45.000000\n",
       "50%     46.000000   47.000000   46.000000   47.000000   46.000000\n",
       "75%     49.000000   48.000000   50.000000   49.000000   50.000000\n",
       "max     54.000000   53.000000   53.000000   55.000000   53.000000"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_arch = path\n",
    "\n",
    "BasicStasts(slicesParser_max_peaksI(path_arch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ratio1-0</th>\n",
       "      <th>ratio2-1</th>\n",
       "      <th>ratio3-2</th>\n",
       "      <th>ratio4-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.736631</td>\n",
       "      <td>1.213793</td>\n",
       "      <td>1.284722</td>\n",
       "      <td>0.802703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.824930</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>1.289474</td>\n",
       "      <td>0.775510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ratio1-0  ratio2-1  ratio3-2  ratio4-3\n",
       "1  0.736631  1.213793  1.284722  0.802703\n",
       "2  0.824930  0.967742  1.289474  0.775510"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes_ratio(slicesParser_amplitudes(path_arch)).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transient1</th>\n",
       "      <th>transient2</th>\n",
       "      <th>transient3</th>\n",
       "      <th>transient4</th>\n",
       "      <th>transient5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transient1 transient2 transient3 transient4 transient5\n",
       "1         19         22         20         18         20\n",
       "2         19         21         21         19         21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicesParser_min_peaksI(path_arch).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no possible callculation\n"
     ]
    }
   ],
   "source": [
    "slicesParser_tau(path_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Discordance Index\n",
    "\n",
    "import statistics\n",
    "\n",
    "WC_amplitud = jasonReader(path_arch)['image']['amplitudes']\n",
    "local_AR = amplitudes_ratio(slicesParser_amplitudes(path_arch))\n",
    "DI = local_AR.std()/statistics.mean(WC_amplitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import statistics\n",
    "\n",
    "list_DI = []\n",
    "fotos_list = os.listdir(path)\n",
    "fotos_list = [x.split('.')[0] for x in fotos_list if 'tif' in x]\n",
    "for nombre_foto in fotos_list[:]:\n",
    "    jasonGenerator(path,  'test.txt')\n",
    "    WC_amplitud = jasonReader(path)['image']['amplitudes']\n",
    "    local_AR = amplitudes_ratio(slicesParser_amplitudes(path))\n",
    "    DI = local_AR.std()/statistics.mean(WC_amplitud)\n",
    "    list_DI.append (DI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ratio1-0    0.101236\n",
       " ratio2-1    0.104679\n",
       " ratio3-2    0.114077\n",
       " ratio4-3    0.101384\n",
       " dtype: float64,\n",
       " ratio1-0    0.101236\n",
       " ratio2-1    0.104679\n",
       " ratio3-2    0.114077\n",
       " ratio4-3    0.101384\n",
       " dtype: float64,\n",
       " ratio1-0    0.101236\n",
       " ratio2-1    0.104679\n",
       " ratio3-2    0.114077\n",
       " ratio4-3    0.101384\n",
       " dtype: float64,\n",
       " ratio1-0    0.101236\n",
       " ratio2-1    0.104679\n",
       " ratio3-2    0.114077\n",
       " ratio4-3    0.101384\n",
       " dtype: float64]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_DI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
