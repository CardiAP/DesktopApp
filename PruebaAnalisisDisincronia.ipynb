{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.94417836 -0.00403217]\n",
      "[ 4.19456056 -0.00439955]\n",
      "[ 4.26439155e+00 -3.49977606e-03]\n",
      "[ 4.62596656e+00 -4.56361780e-03]\n",
      "[ 4.69648076e+00 -4.02215833e-03]\n",
      "[ 4.17274703 -0.00840895]\n",
      "[ 4.17016683 -0.00439883]\n",
      "[ 4.24744132e+00 -3.02840475e-03]\n",
      "[ 4.60253366e+00 -4.37457523e-03]\n",
      "[ 5.10884474 -0.00572488]\n",
      "[ 4.15927445 -0.00772477]\n",
      "[ 4.36139884 -0.00582759]\n",
      "[ 4.19479073e+00 -2.29939519e-03]\n",
      "[ 4.82489606 -0.00557393]\n",
      "[ 5.01398975 -0.00509606]\n",
      "[ 4.10970834 -0.00717182]\n",
      "[ 4.48717212 -0.00695556]\n",
      "[ 4.10780325e+00 -1.81647041e-03]\n",
      "[ 4.53066718e+00 -2.96330107e-03]\n",
      "[ 3.95124372e+00 -3.80083596e-16]\n",
      "[ 3.99222965 -0.00500778]\n",
      "[ 4.46637297 -0.00669466]\n",
      "[ 4.30508398e+00 -3.45701040e-03]\n",
      "[ 4.30693441e+00 -2.91956174e-03]\n",
      "[ 4.39001572e+00 -2.36906863e-03]\n",
      "[ 3.91661263e+00 -3.58517206e-03]\n",
      "[ 4.48332981 -0.00715884]\n",
      "[ 4.33129138e+00 -3.84087669e-03]\n",
      "[ 4.33846772e+00 -3.07179063e-03]\n",
      "[ 4.33222245e+00 -2.18998885e-03]\n",
      "[ 3.90751139e+00 -3.79789521e-03]\n",
      "[ 4.38045114 -0.00639555]\n",
      "[ 4.18214745e+00 -2.79928889e-03]\n",
      "[ 4.44173063e+00 -3.56953860e-03]\n",
      "[ 4.41431685e+00 -2.66709717e-03]\n",
      "[3.82864140e+00 5.32933706e-16]\n",
      "[ 3.89371168e+00 -3.62717365e-03]\n",
      "[ 4.15624819 -0.00427895]\n",
      "[ 3.95384637e+00 -1.13252534e-03]\n",
      "[ 4.38779099e+00 -3.37345939e-03]\n",
      "[ 4.49636531e+00 -3.14520562e-03]\n",
      "[ 3.87981812e+00 -3.50359636e-03]\n",
      "[ 4.10042736e+00 -3.87289335e-03]\n",
      "[ 3.99117646e+00 -1.37991220e-03]\n",
      "[ 4.30022168e+00 -2.93418780e-03]\n",
      "[ 4.91687058 -0.0050798 ]\n",
      "[ 5.57737206 -0.00689686]\n",
      "[ 3.84305878e+00 -2.51119960e-03]\n",
      "[ 4.09288400e+00 -3.67710379e-03]\n",
      "[ 3.80666249e+00 -4.42874175e-17]\n",
      "[ 4.70838448 -0.00513596]\n",
      "[ 5.03793052 -0.00563596]\n",
      "[3.76120012e+00 2.66478400e-16]\n",
      "[ 3.83603240e+00 -2.33307607e-03]\n",
      "[ 4.24531748 -0.00521051]\n",
      "[ 4.01774497e+00 -1.61701445e-03]\n",
      "[ 4.88625977 -0.00610434]\n",
      "[ 5.00224718 -0.00548608]\n",
      "[ 3.76120012e+00 -4.61204104e-16]\n",
      "[ 3.82266843e+00 -1.94189844e-03]\n",
      "[ 4.21583864 -0.0047074 ]\n",
      "[ 4.13732304e+00 -2.43365303e-03]\n",
      "[ 4.93646742 -0.00641627]\n",
      "[ 4.76935474e+00 -4.50850761e-03]\n",
      "[ 3.78418963e+00 -1.04320988e-19]\n",
      "[ 3.85846175e+00 -2.46064554e-03]\n",
      "[ 4.15515487e+00 -3.88480843e-03]\n",
      "[ 4.20392270e+00 -2.79795844e-03]\n",
      "[ 4.94363369 -0.00651791]\n",
      "[ 4.61209009e+00 -3.80746117e-03]\n",
      "[ 3.91928184e+00 -3.45907002e-03]\n",
      "[ 4.14788433e+00 -3.99335180e-03]\n",
      "[ 4.50030045 -0.00483806]\n",
      "[ 4.84919878 -0.00602106]\n",
      "[ 4.25061614e+00 -2.21130227e-03]\n",
      "[ 3.92980523e+00 -3.48812354e-03]\n",
      "[ 4.17376217 -0.00443435]\n",
      "[ 4.62157064 -0.00584087]\n",
      "[ 4.7209332  -0.00521587]\n",
      "[ 4.93772499 -0.00504225]\n",
      "[ 3.96176611 -0.00457445]\n",
      "[ 4.10615502e+00 -3.79269059e-03]\n",
      "[ 4.632811   -0.00621597]\n",
      "[ 4.68603236 -0.00486047]\n",
      "[ 4.85550118e+00 -4.59790364e-03]\n",
      "[ 3.92970103 -0.00433373]\n",
      "[ 4.11135785e+00 -3.87447873e-03]\n",
      "[ 4.59609073 -0.00638579]\n",
      "[ 4.62746928e+00 -4.38617510e-03]\n",
      "[ 4.14577318e+00 -1.64408502e-03]\n",
      "[ 3.82035702e+00 -2.45572747e-03]\n",
      "[ 4.07225225e+00 -3.53454289e-03]\n",
      "[ 4.31859989 -0.00464289]\n",
      "[ 4.62699747e+00 -4.41160799e-03]\n",
      "[ 5.20369172 -0.00627081]\n",
      "[ 3.84756202e+00 -3.50789869e-03]\n",
      "[ 4.00598577e+00 -2.79391593e-03]\n",
      "[ 3.95014480e+00 -1.79372752e-03]\n",
      "[ 4.61403127e+00 -4.40927843e-03]\n",
      "[ 5.1180871  -0.00598243]\n",
      "[ 3.82276168e+00 -3.01469655e-03]\n",
      "[ 4.25684899 -0.00578052]\n",
      "[3.76120012e+00 1.56381596e-17]\n",
      "[ 4.62824485e+00 -4.47832258e-03]\n",
      "[ 5.1556438  -0.00619133]\n",
      "[ 3.8643434  -0.00393067]\n",
      "[ 4.33052119 -0.00653861]\n",
      "[ 3.98810123e+00 -1.53761645e-03]\n",
      "[ 4.56693203e+00 -4.08429572e-03]\n",
      "[ 5.01740661 -0.005623  ]\n",
      "[ 3.90913455 -0.00482968]\n",
      "[ 4.3600323  -0.00653038]\n",
      "[ 4.27394139e+00 -3.53284528e-03]\n",
      "[ 4.76020293 -0.00500822]\n",
      "[ 5.00452329 -0.00560649]\n",
      "[ 3.93330859 -0.00431611]\n",
      "[ 4.25926483 -0.00484675]\n",
      "[ 4.38143191 -0.00438291]\n",
      "[ 4.82817835 -0.00528587]\n",
      "[ 4.89537283 -0.00509994]\n",
      "[ 3.85014760e+00 -7.02160529e-19]\n",
      "[ 3.9969595  -0.00452654]\n",
      "[ 4.19417919e+00 -3.70653673e-03]\n",
      "[ 4.34608058e+00 -4.12470686e-03]\n",
      "[ 4.9524138  -0.00597101]\n",
      "[ 5.11449249 -0.00588304]\n",
      "[3.91202301e+00 1.64983157e-18]\n",
      "[ 4.07600517 -0.00502736]\n",
      "[ 4.21538109e+00 -3.63468539e-03]\n",
      "[ 4.32077119e+00 -3.93197132e-03]\n",
      "[ 4.77542564 -0.00501944]\n",
      "[ 4.62928257e+00 -3.46866728e-03]\n",
      "[5.84494862e-05 1.51968664e-02]\n",
      "[ 4.12662145 -0.00535784]\n",
      "[ 4.18231608e+00 -3.10388272e-03]\n",
      "[ 4.41562929 -0.00447985]\n",
      "[ 4.51918117e+00 -3.62178351e-03]\n",
      "[ 4.59013107e+00 -3.10584688e-03]\n",
      "[3.95124372e+00 2.13377834e-18]\n",
      "[ 4.07310813e+00 -3.72295343e-03]\n",
      "[ 4.25353288e+00 -3.79642021e-03]\n",
      "[ 4.49987893 -0.00491607]\n",
      "[ 4.52994182e+00 -3.68753803e-03]\n",
      "[ 4.60008544e+00 -3.10066874e-03]\n",
      "[5.75605466e-05 1.50808632e-02]\n",
      "[ 4.01892966e+00 -2.82317478e-03]\n",
      "[ 4.29114049 -0.00445021]\n",
      "[ 4.50706468 -0.00496113]\n",
      "[ 4.72635294 -0.00485126]\n",
      "[ 4.75159151e+00 -3.85949385e-03]\n",
      "[ 3.91202301e+00 -3.22912728e-18]\n",
      "[ 4.0067956e+00 -3.5667480e-03]\n",
      "[ 4.21409328e+00 -4.12993012e-03]\n",
      "[ 4.46747179 -0.0049531 ]\n",
      "[ 4.90670215 -0.00604133]\n",
      "[ 4.86262085e+00 -4.56323590e-03]\n",
      "[ 5.12126674e+00 -4.91570405e-03]\n",
      "[ 4.04928999 -0.0057267 ]\n",
      "[ 4.08786703e+00 -3.39432841e-03]\n",
      "[ 4.49084135 -0.00550802]\n",
      "[ 5.02941063 -0.00696504]\n",
      "[ 5.06329597 -0.00567888]\n",
      "[3.78418963e+00 2.67213199e-16]\n",
      "[ 4.04095012 -0.00632145]\n",
      "[ 4.04551130e+00 -3.35752628e-03]\n",
      "[ 4.47679023 -0.00555461]\n",
      "[ 5.03693388 -0.00725378]\n",
      "[ 5.07126657 -0.00585519]\n",
      "[5.47920477e-05 1.43555165e-02]\n",
      "[ 4.04528319 -0.00652222]\n",
      "[ 4.04217470e+00 -3.22091558e-03]\n",
      "[ 4.43988639 -0.0052534 ]\n",
      "[ 5.02531769 -0.00722017]\n",
      "[ 5.31681312 -0.00695251]\n",
      "[3.76120012e+00 3.99350380e-16]\n",
      "[ 3.96647062 -0.00525584]\n",
      "[ 3.97823638e+00 -2.71019400e-03]\n",
      "[ 4.30047245 -0.004325  ]\n",
      "[ 4.70700243 -0.0055712 ]\n",
      "[ 5.05504443 -0.00584551]\n",
      "[3.76120012e+00 2.65646748e-16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leandro/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "# En esta celda se puede probar la funcion de analisis de una imagen\n",
    "\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchrony_analysis\n",
    "import cv2\n",
    "\n",
    "# Path completo donde esta la imagen (incluyendo nombre y extencion)\n",
    "path = './photos_examples/'\n",
    "photo_name = 'c1b000'\n",
    "photo = photo_name + '.tif'\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "slice_width = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 35\n",
    "# Calibracion del tiempo de cada pixel\n",
    "calibration = 1\n",
    "\n",
    "image = cv2.imread(path + photo_name + '.tif')\n",
    "# Select ROI\n",
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "seleted_parameters = cv2.selectROI(image, fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image = image_data.get_image_data(image)\n",
    "image = image_data.crop_vertical(image, x_start, x_end)\n",
    "image = image_data.crop_horizontal(image, y_start, y_end)\n",
    "\n",
    "results = dyssynchrony_analysis.analyze_image(image, min_dist_between_maxs, calibration, slice_width=slice_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jasonGenerator(path,results,photo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = jasonReader(path + 'analysis_result_' + photo_name + '.json')\n",
    "slicesParser_amplitudes(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['image']['max_peaks_positions'])\n",
    "for i in range(0,len(results['slices'])):\n",
    "    array = results['slices'][i]['max_peaks_positions']\n",
    "    print(i,array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(0,len(results['slices'])):\n",
    "    array = results['slices'][i]['intensities']\n",
    "    plt.plot(array) # plotting by columns\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBA ANALISIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se puede probar la funcion de analisis todas las imagenes .tif en un directorio\n",
    "import os\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchrony_analysis\n",
    "import cv2\n",
    "\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "slice_width = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 200\n",
    "\n",
    "# Calibracion del tiempo de cada pixel\n",
    "calibration = 3.1\n",
    "\n",
    "# Path donde estan las imagenes\n",
    "path = \"C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/1 Hz/\"\n",
    "\n",
    "images_paths = [ f'{path}/{file}' for file in os.listdir(path) if file.endswith(\".tif\") ]\n",
    "images = [ cv2.imread(image_path) for image_path in images_paths ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "\n",
    "#Tomamos la primer imagen para seleccionar el recorte elegido el resto de las imagenes se van a recortar igual\n",
    "seleted_parameters = cv2.selectROI(images[0], fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ image_data.get_image_data(image) for image in images ]\n",
    "images = [ image_data.crop_vertical(image, x_start, x_end) for image in images ]\n",
    "images = [ image_data.crop_horizontal(image, y_start, y_end) for image in images ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [(dyssynchrony_analysis.analyze_image(image, min_dist_between_maxs, calibration, slice_width=5), print ('Done')) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de datos\n",
    "Notas: \n",
    "- Image corresponde al análisis de toda la célula y slices corresponde a fetas de esa imagen\n",
    "- intensidades es el valor que resulta de comprimir (sumando) la matriz con las coordenadas de x,y,z de los pixeles \n",
    "- max_peaks_pos es la index de en la lista de intensidades \n",
    "- max_peaks_intensities el valor de intensidad que se corresponde con el pico en la posicion analoga de max_peaks_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodes a dictionary into a jason\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def jasonGenerator(path,results,photo_name):\n",
    "    \"\"\" Generates a .jason file in the path given folder from the a dictionary \"\"\"\n",
    "    with open(path + '/analysis_result_' + photo_name + '.json',\"w\") as miarch:\n",
    "        miarch.write(json.dumps(results, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jasonReader(path):\n",
    "    \"\"\" Reads the .jason generated with jasonGenartor the given path\"\"\"\n",
    "    with open(path,'r') as miarch:\n",
    "        loaded_dict = json.loads(miarch.read())\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_max_peaksI(dictres):\n",
    "#extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x) for x in range(0,len(allSlices[0]['max_peaks_intensities']))]    \n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i] = allSlices[i]['max_peaks_intensities'][0:] \n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_halfpeakstime(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    \n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_half_peaks']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['times_to_half_peaks']\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_amplitudes(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['amplitudes']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['amplitudes']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_min_peaksI(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['min_peaks_intensities']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['min_peaks_intensities']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_peaktime(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_peaks']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['times_to_peaks']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_tau(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['tau_s']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['tau_s']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicStasts(df):\n",
    "    if df.empty == False:\n",
    "        return df.astype('int').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitudes_ratio(df):\n",
    "    df_alt = pd.DataFrame()\n",
    "    for i in range(0,len(list(df))-1):\n",
    "        name = 'ratio' + str(i+1) +'-' + str(i)\n",
    "        df_alt[name] = df[list(df)[i+1]]/df[list(df)[i]]\n",
    "    return df_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/leandro/Documentos/Analisis_de_imagenes/CardiAP/DesktopApp/photos_examples/'\n",
    "photo_name = 'c1d000'\n",
    "photo = photo_name + '.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict = jasonReader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicStasts(slicesParser_max_peaksI(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_ratio(slicesParser_amplitudes(path)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_mean = slicesParser_amplitudes(path).mean()\n",
    "for i in range(0,len(amp_mean)-1):\n",
    "    AR_ind = (1- (amp_mean[i+1])/amp_mean[i])\n",
    "    print (AR_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicesParser_min_peaksI(path).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicesParser_tau(path).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discordance_index(path):\n",
    "    DIs = pd.DataFrame()\n",
    "    for j in range (1, len(slicesParser_amplitudes(path).columns)):\n",
    "        rel_diff = []\n",
    "        for i in range (0, len (slicesParser_amplitudes(path))):\n",
    "            T1 = list(slicesParser_amplitudes(path)['transient'+str(j)])[i]\n",
    "            T2 = list(slicesParser_amplitudes(path)['transient'+str(j+1)])[i]\n",
    "            rel_diff.append((T1-T2)/max(T1,T2))\n",
    "        DIs[j] = rel_diff\n",
    "    return DIs\n",
    "def alternance_ratio(path):\n",
    "    T1_mean = float(slicesParser_amplitudes(path)['transient1'].mean())\n",
    "    T2_mean = float(slicesParser_amplitudes(path)['transient2'].mean())\n",
    "    AR = (abs(T1_mean-T2_mean))/max(T1_mean, T2_mean)\n",
    "    return AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DI_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    print (file)\n",
    "    DI_list.append(discordance_index(dic))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "for index in range(0,len(DI_list)):\n",
    "    file.append([jsons_list[index], (DI_list[index]).std().mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd    \n",
    "\n",
    "df = pd.DataFrame(file, columns= ['photo_name','DI'])\n",
    "df.to_csv(path + 'discordances_indexes.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_defectuosos = []\n",
    "for i in list_archs:\n",
    "    dic = jasonReader(i)\n",
    "    try:\n",
    "        slicesParser_max_peaksI(dic)\n",
    "    except:\n",
    "        arch_defectuosos.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_defectuosos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "AR_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    T1_mean = dic['image']['amplitudes'][0]\n",
    "    T2_mean = dic['image']['amplitudes'][1]\n",
    "    AR_list.append([file, (abs(T1_mean-T2_mean))/max(T1_mean, T2_mean)])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd    \n",
    "\n",
    "df = pd.DataFrame(AR_list, columns= ['photo_name','AR'])\n",
    "df.to_csv(path + 'alternance_ratio.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_index = pd.read_csv('C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/discordances_indexes.csv', encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_ind_from_stats\n",
    "t, p = ttest_ind(DI_5hz_C['DI'], DI_5hz_D['DI'], equal_var=False)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "tau_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    taus = slicesParser_tau(dic)\n",
    "    tau_list.append(taus)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_list[-1].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    taus = dic['image']['tau_s']\n",
    "    tau_list.append([file,sum(taus)/len(taus),slicesParser_tau(dic).mean().mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd    \n",
    "\n",
    "df = pd.DataFrame(tau_list, columns= ['photo_name','tau_wc', 'tau_slices'])\n",
    "df.to_csv(path + 'tau.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import Series\n",
    "\n",
    "from lmfit import Model, Parameter, report_fit\n",
    "\n",
    "def decay(t, N, tau):\n",
    "    return N*np.exp(-t/tau)\n",
    "\n",
    "t = np.linspace(218, 244, num=26)\n",
    "data = [50, 50, 50, 50, 50, 50, 50, 49, 49, 49, 49, 49, 48, 48, 48, 48, 47, 47, 47, 46, 46, 46, 45, 45, 45, 45]\n",
    "\n",
    "model = Model(decay, independent_vars=['t'])\n",
    "result = model.fit(data, t=t, N=10, tau=150)\n",
    "result.plot()\n",
    "print(result.values)\n",
    "\n",
    "result = model.fit(data, t=t,\n",
    "                   N=Parameter('N', value=10),\n",
    "                   tau=Parameter('tau', value=1))\n",
    "report_fit(result.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
