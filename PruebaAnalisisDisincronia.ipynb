{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.23255197e+00 -6.69619771e-04]\n",
      "[ 4.37648490e+00 -9.21622721e-04]\n",
      "[ 2.93225723e+00 -5.22684558e-04]\n",
      "[ 3.65375289e+00 -6.29946815e-04]\n",
      "[ 3.03558323e+00 -5.70839710e-04]\n",
      "[ 3.71002405e+00 -6.19519979e-04]\n",
      "[ 3.10657186e+00 -6.00060767e-04]\n",
      "[ 3.74132782e+00 -6.03690939e-04]\n",
      "[ 3.16265943e+00 -6.24498149e-04]\n",
      "[ 3.94989616e+00 -7.03434517e-04]\n",
      "[ 3.16181326e+00 -5.94326188e-04]\n",
      "[ 4.11975511e+00 -7.89367387e-04]\n",
      "[ 3.20315762e+00 -6.27081528e-04]\n",
      "[ 4.15596165e+00 -7.98054743e-04]\n",
      "[ 3.20160306e+00 -6.23430356e-04]\n",
      "[ 4.21646856e+00 -8.35528657e-04]\n",
      "[ 3.21808557e+00 -6.42925398e-04]\n",
      "[ 4.57306406e+00 -1.04718258e-03]\n",
      "[ 3.22583108e+00 -6.50117661e-04]\n",
      "[ 4.59922849e+00 -1.06290715e-03]\n",
      "[ 3.26790961e+00 -6.96815104e-04]\n",
      "[ 4.55764936e+00 -1.03366525e-03]\n",
      "[ 3.28186310e+00 -7.16770373e-04]\n",
      "[ 4.55336349e+00 -1.02504228e-03]\n",
      "[ 3.33678178e+00 -7.85641629e-04]\n",
      "[ 4.45124670e+00 -9.60290648e-04]\n",
      "[ 3.33777699e+00 -7.81072503e-04]\n",
      "[ 4.46572494e+00 -9.64821476e-04]\n",
      "[ 3.35477742e+00 -7.93059373e-04]\n",
      "[ 4.47918364e+00 -9.70022269e-04]\n",
      "[ 3.33341481e+00 -7.68303642e-04]\n",
      "[ 4.50197085e+00 -9.76833883e-04]\n",
      "[ 3.27249205e+00 -6.78749219e-04]\n",
      "[ 4.55702827e+00 -1.00306711e-03]\n",
      "[ 3.28347657e+00 -6.91748533e-04]\n",
      "[ 4.60731498e+00 -1.02978675e-03]\n",
      "[ 3.27815228e+00 -6.78741928e-04]\n",
      "[ 4.63212550e+00 -1.03447998e-03]\n",
      "[ 3.30801636e+00 -7.00798737e-04]\n",
      "[ 4.75797857e+00 -1.09539409e-03]\n",
      "[ 3.31342472e+00 -6.82395920e-04]\n",
      "[ 4.80752833e+00 -1.11276834e-03]\n",
      "[ 3.33239943e+00 -6.80067756e-04]\n",
      "[ 4.81403495e+00 -1.10031303e-03]\n",
      "[ 3.29951876e+00 -6.28170258e-04]\n",
      "[ 4.58350099e+00 -9.65487094e-04]\n",
      "[ 3.34088821e+00 -6.96259668e-04]\n",
      "[ 4.60607042e+00 -9.88927742e-04]\n",
      "[ 3.33041862e+00 -6.87093259e-04]\n",
      "[ 4.57951485e+00 -9.81056990e-04]\n",
      "[ 3.23884592e+00 -5.79791775e-04]\n",
      "[ 4.51479960e+00 -9.54266682e-04]\n",
      "[ 3.24067817e+00 -5.85405888e-04]\n",
      "[ 4.50407105e+00 -9.49649988e-04]\n",
      "[ 3.24241698e+00 -5.98056482e-04]\n",
      "[ 4.57944492e+00 -1.00255020e-03]\n",
      "[ 3.18161686e+00 -5.45330059e-04]\n",
      "[ 4.40533055e+00 -9.04360521e-04]\n",
      "[ 3.14131764e+00 -5.09549472e-04]\n",
      "[ 4.24454484e+00 -8.21538178e-04]\n",
      "[ 3.12288410e+00 -4.91409919e-04]\n",
      "[ 4.21236586e+00 -8.09514708e-04]\n",
      "[ 3.13096719e+00 -5.07720188e-04]\n",
      "[ 3.80166276e+00 -5.76282358e-04]\n",
      "[ 3.08140058e+00 -4.50135789e-04]\n",
      "[ 4.01297699e+00 -6.93730127e-04]\n",
      "[ 3.07202488e+00 -4.42969267e-04]\n",
      "[ 3.86789172e+00 -6.22567042e-04]\n",
      "[ 3.07362178e+00 -4.46172221e-04]\n",
      "[ 3.83026060e+00 -6.09048387e-04]\n",
      "[ 3.16982786e+00 -5.51217544e-04]\n",
      "[ 3.99768342e+00 -7.02684918e-04]\n",
      "[ 3.20647203e+00 -5.65940989e-04]\n",
      "[ 4.11845482e+00 -7.58257302e-04]\n",
      "[ 3.20335304e+00 -5.44368930e-04]\n",
      "[ 4.37730142e+00 -8.90512230e-04]\n"
     ]
    }
   ],
   "source": [
    "# En esta celda se puede probar la funcion de analisis de una imagen\n",
    "\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchrony_analysis\n",
    "import cv2\n",
    "\n",
    "# Path completo donde esta la imagen (incluyendo nombre y extencion)\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/050320sel/050320c2/'\n",
    "photo_name = '2a000'\n",
    "photo = photo_name + '.tif'\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "slice_width = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 200\n",
    "# Calibracion del tiempo de cada pixel\n",
    "calibration = 4.5\n",
    "\n",
    "image = cv2.imread(path + photo_name + '.tif')\n",
    "# Select ROI\n",
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "seleted_parameters = cv2.selectROI(image, fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image = image_data.get_image_data(image)\n",
    "image = image_data.crop_vertical(image, x_start, x_end)\n",
    "image = image_data.crop_horizontal(image, y_start, y_end)\n",
    "\n",
    "results = dyssynchrony_analysis.analyze_image(image, min_dist_between_maxs, calibration, slice_width=slice_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jasonGenerator(path,results,photo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = jasonReader(path + 'analysis_result_' + photo_name + '.json')\n",
    "slicesParser_amplitudes(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['image']['max_peaks_positions'])\n",
    "for i in range(0,len(results['slices'])):\n",
    "    array = results['slices'][i]['max_peaks_positions']\n",
    "    print(i,array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(0,len(results['slices'])):\n",
    "    array = results['slices'][i]['intensities']\n",
    "    plt.plot(array) # plotting by columns\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBA ANALISIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se puede probar la funcion de analisis todas las imagenes .tif en un directorio\n",
    "import os\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchrony_analysis\n",
    "import cv2\n",
    "\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "slice_width = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 200\n",
    "\n",
    "# Calibracion del tiempo de cada pixel\n",
    "calibration = 3.1\n",
    "\n",
    "# Path donde estan las imagenes\n",
    "path = \"C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/1 Hz/\"\n",
    "\n",
    "images_paths = [ f'{path}/{file}' for file in os.listdir(path) if file.endswith(\".tif\") ]\n",
    "images = [ cv2.imread(image_path) for image_path in images_paths ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "\n",
    "#Tomamos la primer imagen para seleccionar el recorte elegido el resto de las imagenes se van a recortar igual\n",
    "seleted_parameters = cv2.selectROI(images[0], fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ image_data.get_image_data(image) for image in images ]\n",
    "images = [ image_data.crop_vertical(image, x_start, x_end) for image in images ]\n",
    "images = [ image_data.crop_horizontal(image, y_start, y_end) for image in images ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [(dyssynchrony_analysis.analyze_image(image, min_dist_between_maxs, calibration, slice_width=5), print ('Done')) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de datos\n",
    "Notas: \n",
    "- Image corresponde al análisis de toda la célula y slices corresponde a fetas de esa imagen\n",
    "- intensidades es el valor que resulta de comprimir (sumando) la matriz con las coordenadas de x,y,z de los pixeles \n",
    "- max_peaks_pos es la index de en la lista de intensidades \n",
    "- max_peaks_intensities el valor de intensidad que se corresponde con el pico en la posicion analoga de max_peaks_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodes a dictionary into a jason\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def jasonGenerator(path,results,photo_name):\n",
    "    \"\"\" Generates a .jason file in the path given folder from the a dictionary \"\"\"\n",
    "    with open(path + '/analysis_result_' + photo_name + '.json',\"w\") as miarch:\n",
    "        miarch.write(json.dumps(results, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jasonReader(path):\n",
    "    \"\"\" Reads the .jason generated with jasonGenartor the given path\"\"\"\n",
    "    with open(path,'r') as miarch:\n",
    "        loaded_dict = json.loads(miarch.read())\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_max_peaksI(dictres):\n",
    "#extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x) for x in range(0,len(allSlices[0]['max_peaks_intensities']))]    \n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i] = allSlices[i]['max_peaks_intensities'][0:] \n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_halfpeakstime(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    \n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_half_peaks']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['times_to_half_peaks']\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_amplitudes(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['amplitudes']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['amplitudes']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_min_peaksI(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['min_peaks_intensities']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['min_peaks_intensities']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_peaktime(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_peaks']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['times_to_peaks']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_tau(dictres):\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['tau_s']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['tau_s']\n",
    "\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicStasts(df):\n",
    "    if df.empty == False:\n",
    "        return df.astype('int').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitudes_ratio(df):\n",
    "    df_alt = pd.DataFrame()\n",
    "    for i in range(0,len(list(df))-1):\n",
    "        name = 'ratio' + str(i+1) +'-' + str(i)\n",
    "        df_alt[name] = df[list(df)[i+1]]/df[list(df)[i]]\n",
    "    return df_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/home/leandro/Documentos/Analisis_de_imagenes/CardiAP/DesktopApp/photos_examples/'\n",
    "photo_name = 'c1d000'\n",
    "photo = photo_name + '.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict = jasonReader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicStasts(slicesParser_max_peaksI(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amplitudes_ratio(slicesParser_amplitudes(path)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_mean = slicesParser_amplitudes(path).mean()\n",
    "for i in range(0,len(amp_mean)-1):\n",
    "    AR_ind = (1- (amp_mean[i+1])/amp_mean[i])\n",
    "    print (AR_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicesParser_min_peaksI(path).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicesParser_tau(path).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discordance_index(path):\n",
    "    DIs = pd.DataFrame()\n",
    "    for j in range (1, len(slicesParser_amplitudes(path).columns)):\n",
    "        rel_diff = []\n",
    "        for i in range (0, len (slicesParser_amplitudes(path))):\n",
    "            T1 = list(slicesParser_amplitudes(path)['transient'+str(j)])[i]\n",
    "            T2 = list(slicesParser_amplitudes(path)['transient'+str(j+1)])[i]\n",
    "            rel_diff.append((T1-T2)/max(T1,T2))\n",
    "        DIs[j] = rel_diff\n",
    "    return DIs\n",
    "def alternance_ratio(path):\n",
    "    T1_mean = float(slicesParser_amplitudes(path)['transient1'].mean())\n",
    "    T2_mean = float(slicesParser_amplitudes(path)['transient2'].mean())\n",
    "    AR = (abs(T1_mean-T2_mean))/max(T1_mean, T2_mean)\n",
    "    return AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DI_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    print (file)\n",
    "    DI_list.append(discordance_index(dic))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = []\n",
    "for index in range(0,len(DI_list)):\n",
    "    file.append([jsons_list[index], (DI_list[index]).std().mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd    \n",
    "\n",
    "df = pd.DataFrame(file, columns= ['photo_name','DI'])\n",
    "df.to_csv(path + 'discordances_indexes.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_defectuosos = []\n",
    "for i in list_archs:\n",
    "    dic = jasonReader(i)\n",
    "    try:\n",
    "        slicesParser_max_peaksI(dic)\n",
    "    except:\n",
    "        arch_defectuosos.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_defectuosos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "AR_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    T1_mean = dic['image']['amplitudes'][0]\n",
    "    T2_mean = dic['image']['amplitudes'][1]\n",
    "    AR_list.append([file, (abs(T1_mean-T2_mean))/max(T1_mean, T2_mean)])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd    \n",
    "\n",
    "df = pd.DataFrame(AR_list, columns= ['photo_name','AR'])\n",
    "df.to_csv(path + 'alternance_ratio.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_index = pd.read_csv('C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/discordances_indexes.csv', encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, ttest_ind_from_stats\n",
    "t, p = ttest_ind(DI_5hz_C['DI'], DI_5hz_D['DI'], equal_var=False)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "tau_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    taus = slicesParser_tau(dic)\n",
    "    tau_list.append(taus)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_list[-1].mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_list = []\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/Luis/jsons/'\n",
    "jsons_list = os.listdir(path)\n",
    "for file in jsons_list:\n",
    "    path_file = path + file\n",
    "    dic = jasonReader(path_file)\n",
    "    taus = dic['image']['tau_s']\n",
    "    tau_list.append([file,sum(taus)/len(taus),slicesParser_tau(dic).mean().mean()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd    \n",
    "\n",
    "df = pd.DataFrame(tau_list, columns= ['photo_name','tau_wc', 'tau_slices'])\n",
    "df.to_csv(path + 'tau.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
