{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se puede probar la funcion de analisis de una imagen\n",
    "\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchrony_analysis\n",
    "import cv2\n",
    "\n",
    "# Path completo donde esta la imagen (incluyendo nombre y extencion)\n",
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/seleccion/050320sel/050320c2/'\n",
    "photo_name = '2b000.tif'\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "slice_width = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 70\n",
    "\n",
    "# Calibracion del tiempo de cada pixel\n",
    "calibration = 3.1\n",
    "\n",
    "image = cv2.imread(path + photo_name)\n",
    "# Select ROI\n",
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "seleted_parameters = cv2.selectROI(image, fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image = image_data.get_image_data(image)\n",
    "image = image_data.crop_vertical(image, x_start, x_end)\n",
    "image = image_data.crop_horizontal(image, y_start, y_end)\n",
    "\n",
    "results = dyssynchrony_analysis.analyze_image(image, min_dist_between_maxs, calibration, slice_width=slice_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRUEBA ANALISIS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta celda se puede probar la funcion de analisis todas las imagenes .tif en un directorio\n",
    "import os\n",
    "from lib.image import image_data\n",
    "from lib.analysis import dyssynchrony_analysis\n",
    "import cv2\n",
    "\n",
    "# Ancho de la feta a analisar (es un parametro opcional)\n",
    "slice_width = 5\n",
    "\n",
    "# Distancia minima en pixeles entre picos\n",
    "min_dist_between_maxs = 200\n",
    "\n",
    "# Calibracion del tiempo de cada pixel\n",
    "calibration = 3.1\n",
    "\n",
    "# Path donde estan las imagenes\n",
    "path = \"C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/1 Hz/\"\n",
    "\n",
    "images_paths = [ f'{path}/{file}' for file in os.listdir(path) if file.endswith(\".tif\") ]\n",
    "images = [ cv2.imread(image_path) for image_path in images_paths ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromCenter = False\n",
    "showCrosshair = False\n",
    "\n",
    "#Tomamos la primer imagen para seleccionar el recorte elegido el resto de las imagenes se van a recortar igual\n",
    "seleted_parameters = cv2.selectROI(images[0], fromCenter, showCrosshair)\n",
    "\n",
    "# Crop image\n",
    "x_start = int(seleted_parameters[1])\n",
    "x_end = x_start + int(seleted_parameters[3])\n",
    "y_start = int(seleted_parameters[0])\n",
    "y_end = y_start + int(seleted_parameters[2])\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [ image_data.get_image_data(image) for image in images ]\n",
    "images = [ image_data.crop_vertical(image, x_start, x_end) for image in images ]\n",
    "images = [ image_data.crop_horizontal(image, y_start, y_end) for image in images ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [(dyssynchrony_analysis.analyze_image(image, min_dist_between_maxs, calibration, slice_width=5), print ('Done')) for image in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de datos\n",
    "Notas: \n",
    "- Image corresponde al análisis de toda la célula y slices corresponde a fetas de esa imagen\n",
    "- intensidades es el valor que resulta de comprimir (sumando) la matriz con las coordenadas de x,y,z de los pixeles \n",
    "- max_peaks_pos es la index de en la lista de intensidades \n",
    "- max_peaks_intensities el valor de intensidad que se corresponde con el pico en la posicion analoga de max_peaks_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encodes a dictionary into a jason\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Special json encoder for numpy types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def jasonGenerator(path,results):\n",
    "    \"\"\" Generates a .jason file in the path given folder from the a dictionary \"\"\"\n",
    "    with open(path + '/analysis_result.json',\"w\") as miarch:\n",
    "        miarch.write(json.dumps(results, cls=NumpyEncoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jasonReader(path):\n",
    "    \"\"\" Reads the .jason generated with jasonGenartor the given path\"\"\"\n",
    "    with open( path + '/analysis_result.json','r') as miarch:\n",
    "        loaded_dict = json.loads(miarch.read())\n",
    "    return loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_max_peaksI(path):\n",
    "#     read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "\n",
    "#extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x) for x in range(1,len(allSlices[0]['max_peaks_intensities']))]    \n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i] = allSlices[i]['max_peaks_intensities'][1:] \n",
    "        return df_sum\n",
    "\n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_halfpeakstime(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "#     try:\n",
    "    #seting columns names\n",
    "    column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_half_peaks']))]\n",
    "    #define a dataframe\n",
    "    df_sum = pd.DataFrame(columns=column_names)\n",
    "    #populating the dataframe\n",
    "    for i in range(0,len(allSlices)):\n",
    "        df_sum.loc[i+1] = allSlices[i]['times_to_half_peaks']\n",
    "    return df_sum\n",
    "\n",
    "#     except:\n",
    "#         print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_amplitudes(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['amplitudes']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['amplitudes']\n",
    "\n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_min_peaksI(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['min_peaks_intensities']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['min_peaks_intensities']\n",
    "\n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_peaktime(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "\n",
    "    try:\n",
    "        #seting columns names\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['times_to_peaks']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['times_to_peaks']\n",
    "\n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slicesParser_tau(path):\n",
    "    #read the analysis result \n",
    "    dictres = jasonReader(path)\n",
    "    #extract all the slices data\n",
    "    allSlices = dictres['slices']\n",
    "    #seting columns names\n",
    "    try:\n",
    "        column_names = ['transient' + str(x+1) for x in range(0,len(allSlices[0]['tau_s']))]\n",
    "        #define a dataframe\n",
    "        df_sum = pd.DataFrame(columns=column_names)\n",
    "        #populating the dataframe\n",
    "        for i in range(0,len(allSlices)):\n",
    "            df_sum.loc[i+1] = allSlices[i]['tau_s']\n",
    "        \n",
    "        return df_sum\n",
    "    \n",
    "    except:\n",
    "        print('no possible callculation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BasicStasts(df):\n",
    "    if df.empty == False:\n",
    "        return df.astype('int').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discordIndex(df):\n",
    "    return df.iloc[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitudes_ratio(df):\n",
    "    df_alt = pd.DataFrame()\n",
    "    for i in range(0,len(list(df))-1):\n",
    "        name = 'ratio' + str(i+1) +'-' + str(i)\n",
    "        df_alt[name] = df[list(df)[i+1]]/df[list(df)[i]]\n",
    "    return df_alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jasonGenerator(path,results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/Leand/OneDrive/Documentos/Lean/Analizador_imagenes_calcio/seleccion/050320sel/050320c2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dict = jasonReader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transient1</th>\n",
       "      <th>transient2</th>\n",
       "      <th>transient3</th>\n",
       "      <th>transient4</th>\n",
       "      <th>transient5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>21.821429</td>\n",
       "      <td>21.892857</td>\n",
       "      <td>21.678571</td>\n",
       "      <td>21.714286</td>\n",
       "      <td>21.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.362285</td>\n",
       "      <td>1.257254</td>\n",
       "      <td>1.278123</td>\n",
       "      <td>1.410467</td>\n",
       "      <td>1.161553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>20.750000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       transient1  transient2  transient3  transient4  transient5\n",
       "count   28.000000   28.000000   28.000000   28.000000   28.000000\n",
       "mean    21.821429   21.892857   21.678571   21.714286   21.642857\n",
       "std      1.362285    1.257254    1.278123    1.410467    1.161553\n",
       "min     19.000000   19.000000   19.000000   18.000000   19.000000\n",
       "25%     21.000000   21.000000   20.750000   21.000000   21.000000\n",
       "50%     22.000000   22.000000   22.000000   22.000000   22.000000\n",
       "75%     23.000000   23.000000   23.000000   23.000000   22.000000\n",
       "max     24.000000   23.000000   24.000000   24.000000   24.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicStasts(slicesParser_max_peaksI(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ratio1-0    0.149549\n",
       "ratio2-1    0.157308\n",
       "ratio3-2    0.119072\n",
       "ratio4-3    0.129336\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes_ratio(slicesParser_amplitudes(path)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.013660809825434272\n",
      "0.018258770299379057\n",
      "-0.00386402381963169\n",
      "0.03948130998127786\n"
     ]
    }
   ],
   "source": [
    "amp_mean = slicesParser_amplitudes(path).mean()\n",
    "for i in range(0,len(amp_mean)-1):\n",
    "    AR_ind = (1- (amp_mean[i+1])/amp_mean[i])\n",
    "    print (AR_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transient1</th>\n",
       "      <th>transient2</th>\n",
       "      <th>transient3</th>\n",
       "      <th>transient4</th>\n",
       "      <th>transient5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transient1 transient2 transient3 transient4 transient5\n",
       "1         13         13         13         13         13\n",
       "2         14         14         14         14         14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicesParser_min_peaksI(path).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transient1</th>\n",
       "      <th>transient2</th>\n",
       "      <th>transient3</th>\n",
       "      <th>transient4</th>\n",
       "      <th>transient5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.246677</td>\n",
       "      <td>3.666904</td>\n",
       "      <td>4.238366</td>\n",
       "      <td>4.773092</td>\n",
       "      <td>4.569247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.300098</td>\n",
       "      <td>3.724931</td>\n",
       "      <td>4.363729</td>\n",
       "      <td>4.810256</td>\n",
       "      <td>4.781023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transient1  transient2  transient3  transient4  transient5\n",
       "1    3.246677    3.666904    4.238366    4.773092    4.569247\n",
       "2    3.300098    3.724931    4.363729    4.810256    4.781023"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicesParser_tau(path).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transient1    0.059100\n",
       "transient2    0.062882\n",
       "transient3    0.057382\n",
       "transient4    0.040446\n",
       "transient5    0.058202\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicesParser_amplitudes(path).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
